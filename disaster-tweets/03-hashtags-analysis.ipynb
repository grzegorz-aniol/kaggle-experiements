{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotesis - specific tags are more frequent for disaster tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_pattern = re.compile('#\\w+')\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    tokens = re.findall(hashtag_pattern, text)\n",
    "    found_hashtags = filter(lambda token: len(token) > 0 and token[0]=='#', tokens)\n",
    "    found_hashtags = list(map(lambda tag: tag.lstrip('#').lower(), found_hashtags))\n",
    "    return found_hashtags\n",
    "\n",
    "\n",
    "hashtags_series = []\n",
    "all_hashtags = set()\n",
    "PUNCTUATION = string.punctuation\n",
    "hashtags_positive = {}\n",
    "hashtags_negative = {}\n",
    "for _, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    target = int(row['target'])\n",
    "    found_hashtags = extract_hashtags(text)\n",
    "    for h in found_hashtags:\n",
    "        all_hashtags.add(h)\n",
    "    hashtags_series.append(found_hashtags)\n",
    "    output = hashtags_positive if target else hashtags_negative\n",
    "    for hashtag in found_hashtags:\n",
    "        if hashtag in output:\n",
    "            output[hashtag] = output[hashtag] + 1\n",
    "        else:\n",
    "            output[hashtag] = 1\n",
    "\n",
    "df_train['hashtags'] = hashtags_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>@MikeParrActor has confirmed on his twitter saying goodbye 2 ross. Am bloody gobsmacked/devastated #emmerdale</td>\n",
       "      <td>[emmerdale]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>Shame how they took'em from being an intriguing dominant force to a jobbing C-list demolition  https://t.co/1xSSvGIMvb</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>@NEPD_Loyko Texans hope you are wrong. Radio in Houston have him as starter after Foster injury</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>White family (supposedly representing America's GREAT values ) gets blown up in a horrible CGI nuclear strike..... LMFAOOOO!!!!!!!!!!!!</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>@DannyRaynard not bad personally I'd get rid of either hazard or aguero for a better striker than berahino</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>I still need to finish the lover but I'm watching this other drama for 8 hours now and I'm an emotional wreck so the lover needs to wait</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>Demolition Means Progress: Flint Michigan and the Fate of the American Metropolis Highsmith https://t.co/ZvoBMDxHGP</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>Anyone know if Fox ÛÏNewsÛ will be live-streaming tonightÛªs Republican debate online? I want to watch the train wreck.</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>@NorthBayHealth Trauma Center Shines In Response To Multi-Casualty Crash. http://t.co/21B6SKPDUR http://t.co/wBCb3sYtj7</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>@DarrylB1979 yea heard about that..not coming out until 2017 and 2019 ?????? Vampiro is bleeding</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          text  \\\n",
       "2733                             @MikeParrActor has confirmed on his twitter saying goodbye 2 ross. Am bloody gobsmacked/devastated #emmerdale   \n",
       "2365                    Shame how they took'em from being an intriguing dominant force to a jobbing C-list demolition  https://t.co/1xSSvGIMvb   \n",
       "4600                                           @NEPD_Loyko Texans hope you are wrong. Radio in Houston have him as starter after Foster injury   \n",
       "926    White family (supposedly representing America's GREAT values ) gets blown up in a horrible CGI nuclear strike..... LMFAOOOO!!!!!!!!!!!!   \n",
       "4195                                @DannyRaynard not bad personally I'd get rid of either hazard or aguero for a better striker than berahino   \n",
       "7499  I still need to finish the lover but I'm watching this other drama for 8 hours now and I'm an emotional wreck so the lover needs to wait   \n",
       "2343                       Demolition Means Progress: Flint Michigan and the Fate of the American Metropolis Highsmith https://t.co/ZvoBMDxHGP   \n",
       "7483               Anyone know if Fox ÛÏNewsÛ will be live-streaming tonightÛªs Republican debate online? I want to watch the train wreck.   \n",
       "1441                   @NorthBayHealth Trauma Center Shines In Response To Multi-Casualty Crash. http://t.co/21B6SKPDUR http://t.co/wBCb3sYtj7   \n",
       "722                                           @DarrylB1979 yea heard about that..not coming out until 2017 and 2019 ?????? Vampiro is bleeding   \n",
       "\n",
       "         hashtags  target  \n",
       "2733  [emmerdale]       0  \n",
       "2365           []       0  \n",
       "4600           []       0  \n",
       "926            []       1  \n",
       "4195           []       0  \n",
       "7499           []       0  \n",
       "2343           []       1  \n",
       "7483           []       0  \n",
       "1441           []       1  \n",
       "722            []       0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['text', 'hashtags', 'target']].sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate following metrics for hashcodes:\n",
    "- `cnt_positive` - how many tweets labeled as disaster use the hash code.\n",
    "- `cnt_negative` - how many tweets labeled as non-disaster use the hash code.\n",
    "- `all_count` - all tweets having the hashcode.\n",
    "- `positive_fact` - probability of using a hashtag used in disaster tweet.\n",
    "- `negative_fact` - probability of using a hashtag in non-disaster tweet.\n",
    "- `sentiment` - score [-1..1], scaled from `positive_fact` and an indication in which type of tweet the hashtag is used. Zero refers to no usage, or no bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with zeros for not found hashtags\n",
    "hashtag_counts = []\n",
    "for h in all_hashtags:\n",
    "    cnt_positive = hashtags_positive[h] if h in hashtags_positive else 0\n",
    "    cnt_negative = hashtags_negative[h] if h in hashtags_negative else 0\n",
    "    all_count = cnt_positive + cnt_negative\n",
    "    positive_fact = cnt_positive / all_count if all_count > 0 else None\n",
    "    sentiment = 2*(positive_fact - 0.5)\n",
    "    hashtag_counts.append((h, cnt_positive, cnt_negative, all_count, positive_fact, sentiment))\n",
    "\n",
    "df_hashtags = pd.DataFrame(data=hashtag_counts, columns=['hashtag', 'cnt_positive', 'cnt_negative', 'all_count', 'positive_fact', 'sentiment']).set_index('hashtag')\n",
    "df_hashtags.sort_values('all_count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most specific hash tags (with absolut sentiment value >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt_positive</th>\n",
       "      <th>cnt_negative</th>\n",
       "      <th>all_count</th>\n",
       "      <th>positive_fact</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hashtag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nowplaying</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiroshima</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbbo</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobs</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoenix</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quote</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>np</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strategicpatience</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cnt_positive  cnt_negative  all_count  positive_fact  \\\n",
       "hashtag                                                                   \n",
       "nowplaying                    2            21         23       0.086957   \n",
       "hiroshima                    22             0         22       1.000000   \n",
       "earthquake                   19             0         19       1.000000   \n",
       "gbbo                          4            14         18       0.222222   \n",
       "jobs                          0            14         14       0.000000   \n",
       "...                         ...           ...        ...            ...   \n",
       "phoenix                       4             1          5       0.800000   \n",
       "quote                         1             4          5       0.200000   \n",
       "np                            0             5          5       0.000000   \n",
       "science                       5             0          5       1.000000   \n",
       "strategicpatience             4             1          5       0.800000   \n",
       "\n",
       "                   sentiment  \n",
       "hashtag                       \n",
       "nowplaying         -0.826087  \n",
       "hiroshima           1.000000  \n",
       "earthquake          1.000000  \n",
       "gbbo               -0.555556  \n",
       "jobs               -1.000000  \n",
       "...                      ...  \n",
       "phoenix             0.600000  \n",
       "quote              -0.600000  \n",
       "np                 -1.000000  \n",
       "science             1.000000  \n",
       "strategicpatience   0.600000  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = 'all_count >= 5 and (abs(sentiment) >= 0.5)'\n",
    "df_hashtags.query(search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many tweets with most specific hash tags are used in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets: 3330, tweets with relevant hashtags: 587 (18%)\n"
     ]
    }
   ],
   "source": [
    "query_cnt = df_hashtags.query(search_query)['all_count'].sum()\n",
    "all_tweets = df_hashtags['all_count'].sum()\n",
    "print(f'All tweets: {all_tweets}, tweets with relevant hashtags: {query_cnt} ({100*query_cnt/all_tweets:.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_score_result = []\n",
    "for _, row in df_train.iterrows():\n",
    "    hashtags = row['hashtags']\n",
    "    values = []\n",
    "    weights = []\n",
    "    for h in hashtags:\n",
    "        counts = df_hashtags.loc[h]['all_count']\n",
    "        sentiment = df_hashtags.loc[h]['sentiment']\n",
    "        values.append(sentiment)\n",
    "        weights.append(counts)\n",
    "    sentiment = np.average(values, weights=weights) if len(values) > 0 else .0\n",
    "    hashtags_score_result.append(sentiment)\n",
    "df_train['hashtags_sentiment'] = hashtags_score_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtag_positive_score</th>\n",
       "      <th>hashtags_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>4218</td>\n",
       "      <td>drowned</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>Migrants drown at sea after boat capsizes off #Libya http://t.co/t4pv0nrOoV http://t.co/PSeYLYzck4</td>\n",
       "      <td>1</td>\n",
       "      <td>[libya]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>457</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Canada</td>\n",
       "      <td>@ENews Ben Affleck......I know there's a wife/kids and other girls but I can't help it. I've loved him since Armageddon #eonlinechat</td>\n",
       "      <td>0</td>\n",
       "      <td>[eonlinechat]</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>1374</td>\n",
       "      <td>blown%20up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turn on ESPN2 and get blown up</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>7213</td>\n",
       "      <td>natural%20disaster</td>\n",
       "      <td>Oneonta, NY/ Staten Island, NY</td>\n",
       "      <td>its only getting colder and colder and faster and faster and when i first realized it it was like a natural disaster</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>7949</td>\n",
       "      <td>rainstorm</td>\n",
       "      <td>Bridport, England</td>\n",
       "      <td>I want it to rainstorm PLEASE</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>8952</td>\n",
       "      <td>storm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>10335</td>\n",
       "      <td>weapons</td>\n",
       "      <td>ohio</td>\n",
       "      <td>@danagould @WaynesterAtl I agree with background checks. I just think guns or weapons in general are the great equalizer.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>10752</td>\n",
       "      <td>wreckage</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/4sf0rgn8Wo</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>7291</td>\n",
       "      <td>nuclear%20disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Nuclear policy of #Japan without responsibility about Nuclear #Disaster will repeat same #failure.\\n#annonymous #guardian #NYTimes #Reuters</td>\n",
       "      <td>1</td>\n",
       "      <td>[nuclear, japan, disaster, failure, annonymous, guardian, nytimes, reuters]</td>\n",
       "      <td>7.555556</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>4436</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>London</td>\n",
       "      <td>no but seriously I will electrocute half of UK Army's so I can touch bangtan i do not play games when it comes to bts</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             keyword                        location  \\\n",
       "2935   4218             drowned                           Dubai   \n",
       "314     457          armageddon                          Canada   \n",
       "948    1374          blown%20up                             NaN   \n",
       "5061   7213  natural%20disaster  Oneonta, NY/ Staten Island, NY   \n",
       "5570   7949           rainstorm               Bridport, England   \n",
       "6265   8952               storm                             NaN   \n",
       "7216  10335             weapons                            ohio   \n",
       "7519  10752            wreckage                          Mumbai   \n",
       "5112   7291  nuclear%20disaster                             NaN   \n",
       "3090   4436         electrocute                          London   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "2935                                            Migrants drown at sea after boat capsizes off #Libya http://t.co/t4pv0nrOoV http://t.co/PSeYLYzck4   \n",
       "314           @ENews Ben Affleck......I know there's a wife/kids and other girls but I can't help it. I've loved him since Armageddon #eonlinechat   \n",
       "948                                                                                                                 Turn on ESPN2 and get blown up   \n",
       "5061                          its only getting colder and colder and faster and faster and when i first realized it it was like a natural disaster   \n",
       "5570                                                                                                                 I want it to rainstorm PLEASE   \n",
       "6265    kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.   \n",
       "7216                     @danagould @WaynesterAtl I agree with background checks. I just think guns or weapons in general are the great equalizer.   \n",
       "7519      Wreckage 'Conclusively Confirmed' as From MH370: Malaysia PM: Investigators and the families of those who were... http://t.co/4sf0rgn8Wo   \n",
       "5112  #Nuclear policy of #Japan without responsibility about Nuclear #Disaster will repeat same #failure.\\n#annonymous #guardian #NYTimes #Reuters   \n",
       "3090                         no but seriously I will electrocute half of UK Army's so I can touch bangtan i do not play games when it comes to bts   \n",
       "\n",
       "      target  \\\n",
       "2935       1   \n",
       "314        0   \n",
       "948        0   \n",
       "5061       1   \n",
       "5570       0   \n",
       "6265       1   \n",
       "7216       0   \n",
       "7519       1   \n",
       "5112       1   \n",
       "3090       0   \n",
       "\n",
       "                                                                         hashtags  \\\n",
       "2935                                                                      [libya]   \n",
       "314                                                                 [eonlinechat]   \n",
       "948                                                                            []   \n",
       "5061                                                                           []   \n",
       "5570                                                                           []   \n",
       "6265                                                                           []   \n",
       "7216                                                                           []   \n",
       "7519                                                                           []   \n",
       "5112  [nuclear, japan, disaster, failure, annonymous, guardian, nytimes, reuters]   \n",
       "3090                                                                           []   \n",
       "\n",
       "      hashtag_positive_score  hashtags_sentiment  \n",
       "2935                1.000000            1.000000  \n",
       "314                -1.000000           -1.000000  \n",
       "948                 0.000000            0.000000  \n",
       "5061                0.000000            0.000000  \n",
       "5570                0.000000            0.000000  \n",
       "6265                0.000000            0.000000  \n",
       "7216                0.000000            0.000000  \n",
       "7519                0.000000            0.000000  \n",
       "5112                7.555556            0.894737  \n",
       "3090                0.000000            0.000000  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>hashtags_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hashtags_sentiment</th>\n",
       "      <td>0.423561</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target  hashtags_sentiment\n",
       "target              1.000000            0.423561\n",
       "hashtags_sentiment  0.423561            1.000000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['target', 'hashtags_sentiment']].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conflusion: there is many hashtags used more often for disaster tweets than for normal tweets.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt_positive</th>\n",
       "      <th>cnt_negative</th>\n",
       "      <th>all_count</th>\n",
       "      <th>positive_fact</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hashtag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vivaargentina</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tarzana</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ksbynews</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chelsea</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evilempire</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climatechange</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pbs</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nå¼36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cnt_positive  cnt_negative  all_count  positive_fact  sentiment\n",
       "hashtag                                                                       \n",
       "vivaargentina             0             1          1            0.0       -1.0\n",
       "tarzana                   0             1          1            0.0       -1.0\n",
       "ksbynews                  1             0          1            1.0        1.0\n",
       "guardian                  2             0          2            1.0        1.0\n",
       "chelsea                   0             1          1            0.0       -1.0\n",
       "evilempire                0             1          1            0.0       -1.0\n",
       "climatechange             2             0          2            1.0        1.0\n",
       "pbs                       1             0          1            1.0        1.0\n",
       "163                       1             0          1            1.0        1.0\n",
       "nå¼36                     0             1          1            0.0       -1.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hashtags.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashtags.to_csv('./hashtags_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
