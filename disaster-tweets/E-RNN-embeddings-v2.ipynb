{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets sentiment analysis with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GloVe for tweets word embedding and RNN for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "SCRIPT_NAME = 'E-RNN-embeddings-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class GloveEmbeddings:\n",
    "    dict = None\n",
    "    vocabulary = None\n",
    "    word_index = None\n",
    "    vocabulary_size = None\n",
    "    embedding_dim = None\n",
    "    UNKNOWN_TOKEN_INDEX = -1\n",
    "    OUT_OF_VOCABULARY = '<OOV>'\n",
    "    \n",
    "    def __init__(self, dim=100, file_name='../glove.twitter.27B.100d.txt'):\n",
    "        self.embedding_dim = dim\n",
    "        self.dict = self.__load_glove_embeddings(file_name)\n",
    "        if len(self.dict) == 0:\n",
    "            raise Exception('Dictionary is empty')\n",
    "        self.vocabulary = list(self.dict.keys())\n",
    "        self.vocabulary_size = len(self.vocabulary)\n",
    "        self.word_index = {} \n",
    "        self.UNKNOWN_TOKEN_INDEX = self.vocabulary_size + 1\n",
    "        for index, word in enumerate(self.vocabulary):\n",
    "            self.word_index[word]=index\n",
    "\n",
    "    def word_to_token(self, word) -> int:\n",
    "        index = self.word_index.get(word)\n",
    "        if index == None:\n",
    "            return self.UNKNOWN_TOKEN_INDEX\n",
    "        return index + 1 # reserve value 0 for masking\n",
    "    \n",
    "    def token_to_word(self, token) -> str:\n",
    "        if token == 0:\n",
    "            return None\n",
    "        index = token - 1\n",
    "        word = self.vocabulary[index] if index < self.vocabulary_size else self.OUT_OF_VOCABULARY\n",
    "        return word\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.dict[key]\n",
    "\n",
    "    def __load_glove_embeddings(self, path):\n",
    "        embeddings_dict = {}\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], \"float32\")\n",
    "                if vector.shape[0] == self.embedding_dim:\n",
    "                    embeddings_dict[word] = vector\n",
    "        return embeddings_dict                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ['dont', 'you', 'expect', 'this', '?', 'check', 'out', '123', 'page', 'at', 'http://simple.com/site/page.html', 'and', '#others', 'fyi', '@fellow']\n",
      "tokens [349, 16, 2338, 54, 15, 526, 100, 1738, 67, 27, 13054]\n",
      "words ['u', '.', 's', 'national', 'park', 'services', 'tonto', 'national', 'forest', ':', 'stop', 'the', 'annihilation', 'of', 'the', 'salt', 'river', 'wild', 'horse', '...', 'http://t.co/kpqk0c4g0m', 'via', '@change']\n",
      "tokens [52, 2, 138, 2584, 1691, 5694, 6543, 2584, 10051, 3, 362, 14, 223294, 40, 14, 9352, 3571, 2860, 4978, 202]\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "    glove = None\n",
    "\n",
    "    def __init__(self, glove: GloveEmbeddings):\n",
    "        self.glove = glove\n",
    "\n",
    "    def tokenize(self, sentence, skip_oov=True):\n",
    "        \"\"\"Tokenize a sentence. Returns a tuple of words and tokens (numerical IDs)\"\"\"\n",
    "        words = self.tokenizer.tokenize(sentence.lower())\n",
    "        tokens = [glove.word_to_token(w) for w in words]\n",
    "        if skip_oov:\n",
    "            tokens = [token for token in tokens if token != glove.UNKNOWN_TOKEN_INDEX]\n",
    "        return words, tokens\n",
    "\n",
    "\n",
    "def tokenize_tweets_example(tokenizer: Tokenizer):\n",
    "    examples = [\n",
    "        'Don''t you expect this? Check out 123 page at http://simple.com/site/page.html and #others fyi @fellow',\n",
    "        'U.S National Park Services Tonto National Forest: Stop the Annihilation of the Salt River Wild Horse... http://t.co/KPQk0C4G0M via @Change',\n",
    "    ]\n",
    "    for sentence in examples:\n",
    "        words, tokens = tokenizer.tokenize(sentence)\n",
    "        print('words', words)\n",
    "        print('tokens', tokens)\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(glove)\n",
    "\n",
    "tokenize_tweets_example(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def build_glove_embedding_matrix(glove: GloveEmbeddings):\n",
    "    num_tokens = glove.vocabulary_size + 2  # Adding 2 for padding and out-of-vocabulary tokens\n",
    "    emb_dim = glove.embedding_dim\n",
    "    embedding_matrix = np.zeros((num_tokens, emb_dim), dtype=np.float32)\n",
    "    print('Matrix shape', embedding_matrix.shape)\n",
    "    for word in glove.vocabulary:\n",
    "        index = glove.word_to_token(word)\n",
    "        vector = glove[word]\n",
    "        embedding_matrix[index] = vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape (1193515, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = build_glove_embedding_matrix(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding vector dim 100\n",
      "Vocabulary size 1193513\n",
      "Max sequence len 50\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = glove.embedding_dim\n",
    "VOCABULARY_SIZE = glove.vocabulary_size\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "print('Word embedding vector dim', EMBEDDING_DIM)\n",
    "print('Vocabulary size', VOCABULARY_SIZE)\n",
    "print('Max sequence len', MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare train/validation data and find embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "X_raw = df['text'].fillna('')\n",
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def tokenize_input(X, tokenizer: Tokenizer, skip_oov=True, max_seq_len=MAX_SEQ_LEN):\n",
    "    x_tokenized = np.zeros((X.size, max_seq_len), dtype=np.int32)\n",
    "\n",
    "    for i, sentence in enumerate(X):\n",
    "        _, tokens = tokenizer.tokenize(sentence, skip_oov=skip_oov)\n",
    "        for j, token in enumerate(tokens[:max_seq_len]):            \n",
    "            x_tokenized[i, j] = token\n",
    "\n",
    "    return x_tokenized\n",
    "\n",
    "def decode_tokens(tokens, glove: GloveEmbeddings) -> str:\n",
    "    words = [glove.token_to_word(t) for t in tokens if t > 0]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: 128539, known tokens: 109186, unknown tokens: 19353, know ratio: 0.849\n"
     ]
    }
   ],
   "source": [
    "X_all_tokens = tokenize_input(X_raw, tokenizer, skip_oov=False)\n",
    "\n",
    "# Check ratio of known tokens\n",
    "all_items = np.sum(X_all_tokens > 0)\n",
    "known_tokens = np.sum((X_all_tokens > 0) & (X_all_tokens < glove.UNKNOWN_TOKEN_INDEX))\n",
    "unknown_tokens = np.sum(X_all_tokens == glove.UNKNOWN_TOKEN_INDEX)\n",
    "print(f'All tokens: {all_items}, known tokens: {known_tokens}, unknown tokens: {unknown_tokens}, know ratio: {known_tokens/all_items:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  278, 33409,    71,    14,   947,    40,    54,   531,   695,\n",
       "        3837,   292,    76,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tokenize_input(X_raw, tokenizer)\n",
    "\n",
    "X[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max # of tokens for a sentence\n",
    "np.max(np.count_nonzero(X, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Glove dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# del glove\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6851, 50) (6851,) (762, 50) (762,)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(X.shape[0])\n",
    "X_train, X_dev, Y_train, Y_dev, idx_train, idx_test = train_test_split(X, Y, indices, test_size=0.1, shuffle=True)\n",
    "X_raw_dev = X_dev.copy()\n",
    "print(X_train.shape, Y_train.shape, X_dev.shape, Y_dev.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def create_model(use_batch_norm=False, lstm_size=8, dense_size=8, dropout_1=0.5, dropout_2=0.5,\n",
    "          learning_rate=1e-3):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=VOCABULARY_SIZE+2, output_dim=EMBEDDING_DIM, input_length=MAX_SEQ_LEN, \n",
    "                                      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                                      trainable=False, mask_zero=True))\n",
    "    \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size, dropout=dropout_1)))\n",
    "    # model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size, dropout=dropout_2)))\n",
    "    \n",
    "    if use_batch_norm:\n",
    "      model.add(tf.keras.layers.BatchNormalization())\n",
    "    else:\n",
    "      model.add(tf.keras.layers.Dropout(dropout_1))   \n",
    "    \n",
    "    if use_batch_norm:\n",
    "      model.add(tf.keras.layers.Dense(dense_size))\n",
    "      model.add(tf.keras.layers.BatchNormalization())\n",
    "      model.add(tf.keras.layers.Activation('relu'))\n",
    "    else:\n",
    "      model.add(tf.keras.layers.Dense(dense_size, activation='relu'))\n",
    "      model.add(tf.keras.layers.Dropout(dropout_2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def evaluate(X, Y, model):\n",
    "    Y_predict = model.predict(X)\n",
    "    Y_predict = (Y_predict > .5).astype(np.int8)\n",
    "    f1_value = f1_score(Y, Y_predict)\n",
    "    return Y_predict, f1_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_dev, Y_dev, model, batch_size=32, max_epochs=4):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=max_epochs, \n",
    "            validation_data=(X_dev, Y_dev),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1)\n",
    "\n",
    "    _, f1_value = evaluate(X_dev, Y_dev, model)    \n",
    "\n",
    "    print(f\"Validation F1 score: {f1_value}\")\n",
    "\n",
    "    return f1_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 100)           119351500 \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 16)               6976      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,358,621\n",
      "Trainable params: 7,121\n",
      "Non-trainable params: 119,351,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(learning_rate=5e-3,lstm_size=8, dense_size=8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6851, 50), (7613,), (50, 100))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y.shape, (MAX_SEQ_LEN, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('int32')\n",
    "Y_train = Y_train.astype('int32')\n",
    "X_dev = X_dev.astype('int32')\n",
    "Y_dev = Y_dev.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 15s 43ms/step - loss: 0.6331 - accuracy: 0.6342 - val_loss: 0.4985 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.5403 - accuracy: 0.7449 - val_loss: 0.4708 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.5283 - accuracy: 0.7485 - val_loss: 0.4686 - val_accuracy: 0.8005\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.5180 - accuracy: 0.7545 - val_loss: 0.4676 - val_accuracy: 0.7953\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.5064 - accuracy: 0.7584 - val_loss: 0.4796 - val_accuracy: 0.7992\n",
      "24/24 [==============================] - 2s 6ms/step\n",
      "Validation F1 score: 0.7713004484304933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7713004484304933"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(X_train, Y_train, X_dev, Y_dev, model, max_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print('Creating model')\n",
    "    decay_steps = 100\n",
    "    decay_rate = 0.9\n",
    "\n",
    "    initial_learning_rate = trial.suggest_float('initial_learning_rate', 1e-3, 5e-3, log=True)\n",
    "    batch_size = 32 # trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    lstm_size = trial.suggest_categorical('lstm_size', [4, 8, 16, 32])\n",
    "    dense_size = trial.suggest_categorical('dense_size', [8, 16, 32, 64])\n",
    "    use_dropout_1 = trial.suggest_categorical('use_dropout_1', [False, True])\n",
    "    use_dropout_2 = trial.suggest_categorical('use_dropout_2', [False, True])\n",
    "    if use_dropout_1:\n",
    "        dropout_1 = trial.suggest_float('dropout_1', 0.1, 0.5)\n",
    "    else:\n",
    "        dropout_1 = 0\n",
    "    if use_dropout_2:\n",
    "        dropout_2 = trial.suggest_float('dropout_2', 0.1, 0.5)\n",
    "    else:\n",
    "        dropout_2 = 0\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=initial_learning_rate, \n",
    "                                                             decay_steps=decay_steps,\n",
    "                                                             decay_rate=decay_rate)\n",
    "    model = create_model(lstm_size=lstm_size, dense_size=dense_size,\n",
    "                  dropout_1=dropout_1, dropout_2=dropout_2, \n",
    "                  learning_rate=lr_schedule)\n",
    "    f1_score = train(X_train, Y_train, X_dev, Y_dev, model, \n",
    "                        batch_size=batch_size, max_epochs=10)\n",
    "    \n",
    "    print('train is done')\n",
    "    # trial.set_user_attr(\"model\", model)\n",
    "    print('just before objective end')\n",
    "    \n",
    "    return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-08 17:03:06,649] A new study created in memory with name: E-RNN-embeddings-v2\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=SCRIPT_NAME, direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1dde3525d44a53a636c0e1155e2c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 15s 42ms/step - loss: 0.6321 - accuracy: 0.6468 - val_loss: 0.5159 - val_accuracy: 0.7651\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.5247 - accuracy: 0.7593 - val_loss: 0.4744 - val_accuracy: 0.7992\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.5083 - accuracy: 0.7748 - val_loss: 0.4771 - val_accuracy: 0.8005\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4989 - accuracy: 0.7777 - val_loss: 0.4696 - val_accuracy: 0.7913\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4884 - accuracy: 0.7857 - val_loss: 0.4690 - val_accuracy: 0.7927\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4866 - accuracy: 0.7856 - val_loss: 0.4684 - val_accuracy: 0.7927\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4810 - accuracy: 0.7870 - val_loss: 0.4666 - val_accuracy: 0.7940\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.4755 - accuracy: 0.7897 - val_loss: 0.4682 - val_accuracy: 0.7953\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4745 - accuracy: 0.7948 - val_loss: 0.4638 - val_accuracy: 0.7900\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4718 - accuracy: 0.7951 - val_loss: 0.4634 - val_accuracy: 0.7992\n",
      "24/24 [==============================] - 2s 4ms/step\n",
      "Validation F1 score: 0.7567567567567567\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:04:28,190] Trial 0 finished with value: 0.7567567567567567 and parameters: {'initial_learning_rate': 0.001950327154787706, 'lstm_size': 8, 'dense_size': 8, 'use_dropout_1': True, 'use_dropout_2': True, 'dropout_1': 0.42147366232294114, 'dropout_2': 0.3241049327347657}. Best is trial 0 with value: 0.7567567567567567.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 15s 43ms/step - loss: 0.5581 - accuracy: 0.7249 - val_loss: 0.5014 - val_accuracy: 0.7835\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4760 - accuracy: 0.7867 - val_loss: 0.4656 - val_accuracy: 0.7953\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4575 - accuracy: 0.8013 - val_loss: 0.4651 - val_accuracy: 0.8018\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4521 - accuracy: 0.8035 - val_loss: 0.4556 - val_accuracy: 0.8110\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4399 - accuracy: 0.8078 - val_loss: 0.4566 - val_accuracy: 0.7992\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4313 - accuracy: 0.8113 - val_loss: 0.4564 - val_accuracy: 0.8045\n",
      "24/24 [==============================] - 2s 4ms/step\n",
      "Validation F1 score: 0.763157894736842\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:05:21,692] Trial 1 finished with value: 0.763157894736842 and parameters: {'initial_learning_rate': 0.003312722099212413, 'lstm_size': 8, 'dense_size': 16, 'use_dropout_1': True, 'use_dropout_2': True, 'dropout_1': 0.3657346307357521, 'dropout_2': 0.17567079759665966}. Best is trial 1 with value: 0.763157894736842.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 14s 44ms/step - loss: 0.4919 - accuracy: 0.7667 - val_loss: 0.4664 - val_accuracy: 0.7808\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 35ms/step - loss: 0.4155 - accuracy: 0.8126 - val_loss: 0.4646 - val_accuracy: 0.7874\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 8s 36ms/step - loss: 0.3866 - accuracy: 0.8267 - val_loss: 0.4608 - val_accuracy: 0.7927\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 35ms/step - loss: 0.3605 - accuracy: 0.8428 - val_loss: 0.4695 - val_accuracy: 0.7887\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 8s 35ms/step - loss: 0.3378 - accuracy: 0.8578 - val_loss: 0.4797 - val_accuracy: 0.7953\n",
      "24/24 [==============================] - 2s 6ms/step\n",
      "Validation F1 score: 0.7484076433121019\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:06:10,014] Trial 2 finished with value: 0.7484076433121019 and parameters: {'initial_learning_rate': 0.0015554610551235253, 'lstm_size': 32, 'dense_size': 32, 'use_dropout_1': False, 'use_dropout_2': False}. Best is trial 1 with value: 0.763157894736842.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 15s 42ms/step - loss: 0.6333 - accuracy: 0.6402 - val_loss: 0.5323 - val_accuracy: 0.7612\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.5224 - accuracy: 0.7545 - val_loss: 0.4754 - val_accuracy: 0.7913\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4821 - accuracy: 0.7828 - val_loss: 0.4720 - val_accuracy: 0.7887\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4654 - accuracy: 0.7908 - val_loss: 0.4702 - val_accuracy: 0.7848\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4536 - accuracy: 0.7939 - val_loss: 0.4640 - val_accuracy: 0.7927\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4506 - accuracy: 0.7980 - val_loss: 0.4600 - val_accuracy: 0.8005\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4482 - accuracy: 0.7999 - val_loss: 0.4571 - val_accuracy: 0.8071\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4451 - accuracy: 0.7994 - val_loss: 0.4568 - val_accuracy: 0.8058\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4418 - accuracy: 0.8019 - val_loss: 0.4561 - val_accuracy: 0.8110\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4373 - accuracy: 0.8070 - val_loss: 0.4556 - val_accuracy: 0.8163\n",
      "24/24 [==============================] - 2s 4ms/step\n",
      "Validation F1 score: 0.7805642633228839\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:07:33,205] Trial 3 finished with value: 0.7805642633228839 and parameters: {'initial_learning_rate': 0.0010470517028874917, 'lstm_size': 8, 'dense_size': 8, 'use_dropout_1': True, 'use_dropout_2': False, 'dropout_1': 0.2530360774273983}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 16s 47ms/step - loss: 0.5293 - accuracy: 0.7475 - val_loss: 0.4741 - val_accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.4584 - accuracy: 0.7902 - val_loss: 0.4577 - val_accuracy: 0.8045\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 8s 36ms/step - loss: 0.4465 - accuracy: 0.7997 - val_loss: 0.4547 - val_accuracy: 0.8110\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.4314 - accuracy: 0.8098 - val_loss: 0.4629 - val_accuracy: 0.8071\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.4244 - accuracy: 0.8116 - val_loss: 0.4530 - val_accuracy: 0.7966\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.4156 - accuracy: 0.8158 - val_loss: 0.4601 - val_accuracy: 0.8005\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 7s 30ms/step - loss: 0.4167 - accuracy: 0.8162 - val_loss: 0.4590 - val_accuracy: 0.8031\n",
      "24/24 [==============================] - 2s 4ms/step\n",
      "Validation F1 score: 0.7495961227786754\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:08:35,515] Trial 4 finished with value: 0.7495961227786754 and parameters: {'initial_learning_rate': 0.004131122216436542, 'lstm_size': 16, 'dense_size': 64, 'use_dropout_1': True, 'use_dropout_2': True, 'dropout_1': 0.4109258738566074, 'dropout_2': 0.17383524624359298}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 16s 49ms/step - loss: 0.5197 - accuracy: 0.7476 - val_loss: 0.4936 - val_accuracy: 0.7664\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4474 - accuracy: 0.7962 - val_loss: 0.4672 - val_accuracy: 0.7953\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4286 - accuracy: 0.8072 - val_loss: 0.4644 - val_accuracy: 0.7940\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4187 - accuracy: 0.8104 - val_loss: 0.4584 - val_accuracy: 0.7953\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4066 - accuracy: 0.8164 - val_loss: 0.4583 - val_accuracy: 0.7913\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.4034 - accuracy: 0.8232 - val_loss: 0.4604 - val_accuracy: 0.7900\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.3945 - accuracy: 0.8243 - val_loss: 0.4610 - val_accuracy: 0.7940\n",
      "24/24 [==============================] - 3s 6ms/step\n",
      "Validation F1 score: 0.7579908675799087\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:09:44,688] Trial 5 finished with value: 0.7579908675799087 and parameters: {'initial_learning_rate': 0.00105465725506554, 'lstm_size': 32, 'dense_size': 16, 'use_dropout_1': True, 'use_dropout_2': False, 'dropout_1': 0.22111520072282187}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 14s 43ms/step - loss: 0.5466 - accuracy: 0.7284 - val_loss: 0.4743 - val_accuracy: 0.7966\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4507 - accuracy: 0.7977 - val_loss: 0.4763 - val_accuracy: 0.7756\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.4227 - accuracy: 0.8170 - val_loss: 0.4610 - val_accuracy: 0.7927\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.4045 - accuracy: 0.8248 - val_loss: 0.4630 - val_accuracy: 0.7913\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.3880 - accuracy: 0.8383 - val_loss: 0.4644 - val_accuracy: 0.7966\n",
      "24/24 [==============================] - 2s 5ms/step\n",
      "Validation F1 score: 0.7561728395061729\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:10:31,270] Trial 6 finished with value: 0.7561728395061729 and parameters: {'initial_learning_rate': 0.0013869655861712463, 'lstm_size': 16, 'dense_size': 8, 'use_dropout_1': False, 'use_dropout_2': True, 'dropout_2': 0.17778060454300065}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 16s 47ms/step - loss: 0.5238 - accuracy: 0.7466 - val_loss: 0.4985 - val_accuracy: 0.7861\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.4635 - accuracy: 0.7892 - val_loss: 0.4639 - val_accuracy: 0.8084\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 8s 37ms/step - loss: 0.4462 - accuracy: 0.7965 - val_loss: 0.4747 - val_accuracy: 0.8058\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4311 - accuracy: 0.8048 - val_loss: 0.4799 - val_accuracy: 0.7940\n",
      "24/24 [==============================] - 2s 6ms/step\n",
      "Validation F1 score: 0.770440251572327\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:11:14,995] Trial 7 finished with value: 0.770440251572327 and parameters: {'initial_learning_rate': 0.001434448650583901, 'lstm_size': 32, 'dense_size': 32, 'use_dropout_1': True, 'use_dropout_2': False, 'dropout_1': 0.39002135787386205}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 15s 43ms/step - loss: 0.4961 - accuracy: 0.7686 - val_loss: 0.4707 - val_accuracy: 0.7874\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.4122 - accuracy: 0.8210 - val_loss: 0.4762 - val_accuracy: 0.7822\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.3871 - accuracy: 0.8336 - val_loss: 0.4596 - val_accuracy: 0.7953\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 33ms/step - loss: 0.3652 - accuracy: 0.8470 - val_loss: 0.4682 - val_accuracy: 0.7966\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 7s 34ms/step - loss: 0.3475 - accuracy: 0.8558 - val_loss: 0.4767 - val_accuracy: 0.7835\n",
      "24/24 [==============================] - 2s 5ms/step\n",
      "Validation F1 score: 0.7475728155339806\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:12:02,038] Trial 8 finished with value: 0.7475728155339806 and parameters: {'initial_learning_rate': 0.002028096564061628, 'lstm_size': 16, 'dense_size': 64, 'use_dropout_1': False, 'use_dropout_2': False}. Best is trial 3 with value: 0.7805642633228839.\n",
      "Creating model\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 16s 50ms/step - loss: 0.5666 - accuracy: 0.7273 - val_loss: 0.4769 - val_accuracy: 0.7887\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4936 - accuracy: 0.7789 - val_loss: 0.4732 - val_accuracy: 0.8084\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.4827 - accuracy: 0.7854 - val_loss: 0.4640 - val_accuracy: 0.7927\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 7s 35ms/step - loss: 0.4665 - accuracy: 0.7964 - val_loss: 0.4992 - val_accuracy: 0.7900\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 8s 35ms/step - loss: 0.4521 - accuracy: 0.8019 - val_loss: 0.4694 - val_accuracy: 0.8005\n",
      "24/24 [==============================] - 2s 5ms/step\n",
      "Validation F1 score: 0.7459807073954985\n",
      "train is done\n",
      "just before objective end\n",
      "[I 2024-05-08 17:12:52,701] Trial 9 finished with value: 0.7459807073954985 and parameters: {'initial_learning_rate': 0.002740951049952777, 'lstm_size': 32, 'dense_size': 8, 'use_dropout_1': True, 'use_dropout_2': True, 'dropout_1': 0.41002476969915813, 'dropout_2': 0.47170773284215894}. Best is trial 3 with value: 0.7805642633228839.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Best score: 0.7805642633228839\n",
      "-> Optimal network parameters: \n",
      "{'dense_size': 8,\n",
      " 'dropout_1': 0.2530360774273983,\n",
      " 'initial_learning_rate': 0.0010470517028874917,\n",
      " 'lstm_size': 8,\n",
      " 'use_dropout_1': True,\n",
      " 'use_dropout_2': False}\n",
      "-> Best learning parameters: \n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(f'-> Best score: {trial.value}')\n",
    "print(f'-> Optimal network parameters: ')\n",
    "pprint.pprint(trial.params)\n",
    "print(f'-> Best learning parameters: ')\n",
    "pprint.pprint(trial.user_attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with optimal hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "215/215 [==============================] - 35s 115ms/step - loss: 0.5997 - accuracy: 0.6862 - val_loss: 0.4880 - val_accuracy: 0.7769\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 16s 73ms/step - loss: 0.4959 - accuracy: 0.7730 - val_loss: 0.4518 - val_accuracy: 0.7992\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 17s 77ms/step - loss: 0.4671 - accuracy: 0.7910 - val_loss: 0.4584 - val_accuracy: 0.7769\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 15s 67ms/step - loss: 0.4515 - accuracy: 0.7971 - val_loss: 0.4277 - val_accuracy: 0.8163\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 13s 59ms/step - loss: 0.4410 - accuracy: 0.8065 - val_loss: 0.4288 - val_accuracy: 0.8163\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 12s 56ms/step - loss: 0.4366 - accuracy: 0.8053 - val_loss: 0.4192 - val_accuracy: 0.8228\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 12s 57ms/step - loss: 0.4221 - accuracy: 0.8145 - val_loss: 0.4194 - val_accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 13s 61ms/step - loss: 0.4210 - accuracy: 0.8167 - val_loss: 0.4214 - val_accuracy: 0.8123\n",
      "24/24 [==============================] - 4s 8ms/step\n",
      "Validation F1 score: 0.7853736089030207\n"
     ]
    }
   ],
   "source": [
    "the_best_model = create_model(lstm_size=8, dense_size=8,\n",
    "                dropout_1=0.25, dropout_2=0, \n",
    "                learning_rate=1e-3)\n",
    "f1_value = train(X_train, Y_train, X_dev, Y_dev, the_best_model, batch_size=32, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predication on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_results(X, Y, Y_pred):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(Y, Y_pred)\n",
    "\n",
    "    # Compute other metrics\n",
    "    accuracy = accuracy_score(Y, Y_pred)\n",
    "    precision = precision_score(Y, Y_pred, average='macro')\n",
    "    recall = recall_score(Y, Y_pred, average='macro')\n",
    "    f1 = f1_score(Y, Y_pred, average='macro')\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.8228346456692913\n",
      "Precision: 0.8229220779220779\n",
      "Recall: 0.8141790154221975\n",
      "F1 Score: 0.8172678100381026\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_predict, f1_value = evaluate(X_dev, Y_dev, the_best_model)\n",
    "evaluate_final_results(X_dev, Y_dev, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   194  23317     94     30  16465      2     80     59 197632    412\n",
      "     27 372151    398     12   3337     67 662820    235   9536     11\n",
      "    856 372151      2     89    665      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n",
      "oh gio was my backup . but with skc next and bwp getting a crack at nycfc + injury i went bwp . lol wrong\n",
      "@JJ_DIRTY @MLSTransfers @greggmair oh Gio was my backup. But with SKC next and BWP getting a crack at NYCFC + injury I went BWP. Lol wrong\n"
     ]
    }
   ],
   "source": [
    "print(X_raw_dev[0])\n",
    "print(decode_tokens(X_raw_dev[0], glove))\n",
    "print(X_raw.iloc[idx_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentences = np.apply_along_axis(lambda tokens: decode_tokens(tokens, glove), axis=1, arr=X_raw_dev)\n",
    "original_sentences = np.apply_along_axis(lambda idx: X_raw.iloc[idx], axis=0, arr=idx_test)\n",
    "result = pd.DataFrame(np.column_stack((original_sentences, decoded_sentences, Y_dev, Y_predict)), columns=['text', 'decoded', 'y', 'y_pred'])\n",
    "result = result.query('y != y_pred')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>decoded</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Chinas stock market crash this summer has sparked interest from bargain hunters and bulls betting on a rebound. D_ http://t.co/1yggZziZ9o</td>\n",
       "      <td>china stock market crash this summer has sparked interest from bargain hunters and bulls betting on a reb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\\n \\n#FARRAKHAN #QUOTE</td>\n",
       "      <td>who is bringing the tornadoes and floods . who is bringing the climate change . god is after america he i</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Offers : http://t.co/Gl3C1vc88P #8392 Deluxe Toilet Safety Support/Health/Home/Bathroom/Support/Elderly/Injured/S_ http://t.co/vihdoKScCC</td>\n",
       "      <td>offers : deluxe toilet safety support / health / home / bathroom / support / elderly / injured / s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Heres how media in Pakistan covered the capture of terrorist Mohammed Naved http://t.co/f7WqpCEkg2</td>\n",
       "      <td>here how media in pakistan covered the capture of terrorist mohammed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Swansea plot hijack transfer move for Southampton target Virgil van Dijk http://t.co/PVmr38LnvA</td>\n",
       "      <td>swansea   plot hijack transfer move for southampton target virgil van dijk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>my dad said I look thinner than usual but really im over here like http://t.co/bnwyGx6luh</td>\n",
       "      <td>my dad said i look thinner than usual but really im over here like</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>'There was a small earthquake in LA but don't worry Emmy Rossum is fine'</td>\n",
       "      <td>' there was a small earthquake in la but worry emmy rossum is fine '</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>@YoungHeroesID LAVA BLAST dan POWER RED #PantherAttack @Mirmanda11 @evaaaSR</td>\n",
       "      <td>lava blast dan power red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>I can't drown my demons they know how to swim</td>\n",
       "      <td>i drown my demons they know how to swim</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>'I came to kill Indians...for FUN': Video of smirking and remorseless Pakistani killer shows him boasting. http://t.co/FPjLwOXKlg</td>\n",
       "      <td>' i came to kill indians for fun ' : video of smirking and pakistani killer shows him boasting .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "562  Chinas stock market crash this summer has sparked interest from bargain hunters and bulls betting on a rebound. D_ http://t.co/1yggZziZ9o   \n",
       "742     Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\\n \\n#FARRAKHAN #QUOTE   \n",
       "135     Offers : http://t.co/Gl3C1vc88P #8392 Deluxe Toilet Safety Support/Health/Home/Bathroom/Support/Elderly/Injured/S_ http://t.co/vihdoKScCC   \n",
       "290                                           Heres how media in Pakistan covered the capture of terrorist Mohammed Naved http://t.co/f7WqpCEkg2   \n",
       "544                                           Swansea plot hijack transfer move for Southampton target Virgil van Dijk http://t.co/PVmr38LnvA   \n",
       "268                                                       my dad said I look thinner than usual but really im over here like http://t.co/bnwyGx6luh   \n",
       "760                                                                        'There was a small earthquake in LA but don't worry Emmy Rossum is fine'   \n",
       "636                                                                     @YoungHeroesID LAVA BLAST dan POWER RED #PantherAttack @Mirmanda11 @evaaaSR   \n",
       "264                                                                                                   I can't drown my demons they know how to swim   \n",
       "592               'I came to kill Indians...for FUN': Video of smirking and remorseless Pakistani killer shows him boasting. http://t.co/FPjLwOXKlg   \n",
       "\n",
       "                                                                                                       decoded  \\\n",
       "562  china stock market crash this summer has sparked interest from bargain hunters and bulls betting on a reb   \n",
       "742  who is bringing the tornadoes and floods . who is bringing the climate change . god is after america he i   \n",
       "135         offers : deluxe toilet safety support / health / home / bathroom / support / elderly / injured / s   \n",
       "290                                       here how media in pakistan covered the capture of terrorist mohammed   \n",
       "544                               swansea   plot hijack transfer move for southampton target virgil van dijk   \n",
       "268                                         my dad said i look thinner than usual but really im over here like   \n",
       "760                                       ' there was a small earthquake in la but worry emmy rossum is fine '   \n",
       "636                                                                                   lava blast dan power red   \n",
       "264                                                                    i drown my demons they know how to swim   \n",
       "592           ' i came to kill indians for fun ' : video of smirking and pakistani killer shows him boasting .   \n",
       "\n",
       "     y y_pred  \n",
       "562  0      1  \n",
       "742  0      1  \n",
       "135  1      0  \n",
       "290  0      1  \n",
       "544  1      0  \n",
       "268  1      0  \n",
       "760  1      0  \n",
       "636  1      0  \n",
       "264  1      0  \n",
       "592  1      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "result.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model):\n",
    "    df_test = pd.read_csv('./test.csv', index_col='id')\n",
    "    df_test.fillna({'text': '', 'keyword': '', 'location': ''}, inplace=True)\n",
    "    X_raw_test = df_test['text'].to_numpy()\n",
    "    X_test = tokenize_input(X_raw_test, tokenizer)\n",
    "\n",
    "    Y_test_predict = model(X_test)\n",
    "    Y_test_predict = tf.cast(Y_test_predict > .5, tf.int32)\n",
    "\n",
    "    df_example = pd.read_csv('./sample_submission.csv')\n",
    "    df_example['target'] = Y_test_predict\n",
    "\n",
    "    df_example.to_csv(f'./{SCRIPT_NAME}-submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(the_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
