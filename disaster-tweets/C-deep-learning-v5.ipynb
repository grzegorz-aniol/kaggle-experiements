{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster tweets DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 14:41:55.769099: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-27 14:41:55.789354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/gangel/anaconda3/envs/machine-learning-1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import base, feature_extraction, ensemble, model_selection, pipeline, compose, preprocessing, metrics\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "import tensorflow as tf\n",
    "from embedding_transformer import Doc2VecTransformer\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import optuna\n",
    "import pprint\n",
    "\n",
    "SCRIPT_NAME='DL-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>positive_factor</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>missing_location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_content</th>\n",
       "      <th>...</th>\n",
       "      <th>punct_factor</th>\n",
       "      <th>ann_count</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>tokens_count</th>\n",
       "      <th>stop_words_factor</th>\n",
       "      <th>clean_tokens_factor</th>\n",
       "      <th>url_domains</th>\n",
       "      <th>url_redirects_count</th>\n",
       "      <th>hashtags_sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.615385</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.590909</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.647059</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword  positive_factor location country state city  missing_location  \\\n",
       "id                                                                          \n",
       "0                       0.5                                             1   \n",
       "1                       0.5                                             1   \n",
       "2                       0.5                                             1   \n",
       "3                       0.5                                             1   \n",
       "4                       0.5                                             1   \n",
       "\n",
       "                                                 text  \\\n",
       "id                                                      \n",
       "0   Our Deeds are the Reason of this #earthquake M...   \n",
       "1              Forest fire near La Ronge Sask. Canada   \n",
       "2   All residents asked to 'shelter in place' are ...   \n",
       "3   13,000 people receive #wildfires evacuation or...   \n",
       "4   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "id                                                      \n",
       "0          deed reason earthquake may allah forgive u   \n",
       "1               forest fire near la ronge sask canada   \n",
       "2   resident asked shelter place notified officer ...   \n",
       "3   people receive wildfire evacuation order calif...   \n",
       "4   got sent photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                         text_content  ...  punct_factor  \\\n",
       "id                                                     ...                 \n",
       "0   Our Deeds are the Reason of this #earthquake M...  ...      0.017544   \n",
       "1              Forest fire near La Ronge Sask. Canada  ...      0.031250   \n",
       "2   All residents asked to 'shelter in place' are ...  ...      0.026786   \n",
       "3   13,000 people receive #wildfires evacuation or...  ...      0.035088   \n",
       "4   Just got sent this photo from Ruby #Alaska as ...  ...      0.027778   \n",
       "\n",
       "    ann_count  urls_count  tokens_count  stop_words_factor  \\\n",
       "id                                                           \n",
       "0           0           0            13           0.384615   \n",
       "1           0           0             7           0.000000   \n",
       "2           0           0            22           0.409091   \n",
       "3           0           0             9           0.111111   \n",
       "4           0           0            17           0.352941   \n",
       "\n",
       "    clean_tokens_factor  url_domains  url_redirects_count  hashtags_sentiment  \\\n",
       "id                                                                              \n",
       "0              0.615385                                 0            1.000000   \n",
       "1              1.000000                                 0            0.000000   \n",
       "2              0.590909                                 0            0.000000   \n",
       "3              0.888889                                 0            1.000000   \n",
       "4              0.647059                                 0            0.714286   \n",
       "\n",
       "   target  \n",
       "id         \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train_enriched.csv', index_col='id')\n",
    "df_train.fillna({'keyword': '', 'location': '', 'country': '', 'state': '', 'city': '', 'url_domains': '', 'clean_text': ''}, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = None\n",
    "with open('./train-text-embeddings.pkl', 'rb') as fin:\n",
    "    text_embedding = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embedding), len(text_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalEmbeddingTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, data):\n",
    "        # Store the embeddings and mode\n",
    "        self.data = data\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting necessary, return self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X, self.data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (7613, 554)\n",
      "X_train type=<class 'numpy.ndarray'>, shape=(7613, 554)\n",
      "Y_train shape=(7613,)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\n",
    "    'country',\n",
    "    'state',\n",
    "]\n",
    "numerical_features = [\n",
    "    'text_length', \n",
    "    # 'ann_count',\n",
    "    # 'url_redirects_count',\n",
    "    # 'stop_words_factor',\n",
    "    'positive_factor',\n",
    "    'hashtags_sentiment'\n",
    "]\n",
    "\n",
    "# text_vec = feature_extraction.text.TfidfVectorizer(max_features=2000)\n",
    "# text_vec = Doc2VecTransformer(vector_size=2000)\n",
    "# text_vec = feature_extraction.text.CountVectorizer(max_features=1000)\n",
    "# domains_vec = feature_extraction.text.TfidfVectorizer(max_features=100)\n",
    "# domains_vec = feature_extraction.text.CountVectorizer(max_features=100)\n",
    "\n",
    "column_transformer = compose.ColumnTransformer(transformers=[\n",
    "    # ('text_vec', text_vec, 'clean_text'),\n",
    "    # ('domains_vec', domains_vec, 'url_domains'),\n",
    "    ('one_hot', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "    ('numerical', preprocessing.StandardScaler(), numerical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "embedding_transformer = ConditionalEmbeddingTransformer(text_embedding)\n",
    "\n",
    "transformer = pipeline.Pipeline([\n",
    "    ('columns', column_transformer),\n",
    "    ('text_embedding', embedding_transformer)\n",
    "])\n",
    "\n",
    "transformer.fit(df_train)\n",
    "X_train = transformer.transform(df_train)\n",
    "print('X_train shape', X_train.shape)\n",
    "\n",
    "Y_train = df_train['target']\n",
    "\n",
    "print(f'X_train type={type(X_train)}, shape={X_train.shape}')\n",
    "print(f'Y_train shape={Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X_train.shape[1]\n",
    "OUTPUT_SIZE = 1\n",
    "HIDDEN_LAYER_SIZE = 16\n",
    "BATCH_SIZE= 2 # int(0.1*X_train.shape[0])\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return tf.cast(tf.greater(tf.nn.sigmoid(x), .5), tf.int32)\n",
    "\n",
    "\n",
    "def build_model(hidden_layers=HIDDEN_LAYER_SIZE, use_dropout=False, dropout_rate=0.1, learning_rate=1e-3, use_emma=False, emma_momentum=0.99):\n",
    "    layers = [\n",
    "        tf.keras.layers.Dense(hidden_layers, input_shape=(INPUT_SIZE,), activation='relu'),\n",
    "        tf.keras.layers.Dense(hidden_layers, activation='relu'),\n",
    "        tf.keras.layers.Dense(OUTPUT_SIZE, activation='linear')\n",
    "    ]\n",
    "    if use_dropout:\n",
    "        layers = [\n",
    "            layers[0],\n",
    "            tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "            layers[1],\n",
    "            tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "            layers[2]\n",
    "        ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, use_ema=use_emma, ema_momentum=emma_momentum),                 \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics='accuracy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    use_dropout = True # trial.suggest_categorical('use_dropout', [True, False])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4) if use_dropout else .0\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    hidden_layer_size = HIDDEN_LAYER_SIZE\n",
    "    batch_size = trial.suggest_categorical('batch_size', [2, 4, 8])\n",
    "    use_emma = False # trial.suggest_categorical('use_emma', [True, False])\n",
    "    emma_momentum = .999 # trial.suggest_float('emma_momentum', 0.9, 0.9999, log=True) if use_emma else 0.999\n",
    "\n",
    "    k = 5  # Number of folds\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    cvscores = []\n",
    "\n",
    "    model = build_model(hidden_layers=hidden_layer_size, use_dropout=use_dropout, dropout_rate=dropout_rate, \n",
    "                        learning_rate=learning_rate, use_emma=use_emma, emma_momentum=emma_momentum)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "    for index, datasets in enumerate(kfold.split(X_train, Y_train)):\n",
    "        train, test = datasets\n",
    "        X_train_set = X_train[train]\n",
    "        Y_train_set = Y_train[train]\n",
    "        X_test_set = X_train[test]\n",
    "        Y_test_set = Y_train[test]\n",
    "        # print(f'---- step {index+1} of {k}')\n",
    "        # print(f'train size: {len(X_train_set)}, test size: {len(X_test_set)}')\n",
    "        \n",
    "        model.fit(X_train_set, Y_train_set, batch_size=batch_size, epochs=MAX_EPOCHS, \n",
    "                validation_data=(X_test_set, Y_test_set),\n",
    "                callbacks=[early_stopping], \n",
    "                verbose=0)\n",
    "\n",
    "        Y_predict = sigmoid(model(X_test_set))\n",
    "\n",
    "        f1_score = metrics.f1_score(Y_test_set, Y_predict)\n",
    "\n",
    "        # print(f\"Validation F1: {f1_score}\")\n",
    "\n",
    "        cvscores.append(f1_score)\n",
    "\n",
    "    score = np.mean(cvscores)\n",
    "    # print(f\"Mean cross-validation F1 score: {score}\")\n",
    "    # print(f\"Standard deviation of cross-validation score: {tf.math.reduce_std(cvscores)}\")\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:11:17,704] A new study created in memory with name: no-name-1bedf0b7-ebc1-4980-9cd8-d0477840ccec\n",
      "Best trial: 0. Best value: 0.840581:  10%|█         | 1/10 [01:43<15:32, 103.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:13:01,301] Trial 0 finished with value: 0.8405809951239277 and parameters: {'dropout_rate': 0.2582012910782223, 'learning_rate': 0.0004393653708624279, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  20%|██        | 2/10 [02:50<10:56, 82.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:14:08,250] Trial 1 finished with value: 0.834120088998499 and parameters: {'dropout_rate': 0.1946338351937873, 'learning_rate': 5.6261992845547525e-05, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  30%|███       | 3/10 [03:02<05:51, 50.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:14:20,631] Trial 3 finished with value: 0.8319793933959241 and parameters: {'dropout_rate': 0.32295303347736726, 'learning_rate': 0.001105322306357548, 'batch_size': 2}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  40%|████      | 4/10 [03:20<03:44, 37.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:14:38,303] Trial 4 finished with value: 0.8383829852075013 and parameters: {'dropout_rate': 0.15430687116186914, 'learning_rate': 0.00334043129016256, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  50%|█████     | 5/10 [04:27<03:59, 47.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:15:44,917] Trial 5 finished with value: 0.8385629229713294 and parameters: {'dropout_rate': 0.10749707959041259, 'learning_rate': 0.001304653524994113, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  60%|██████    | 6/10 [04:51<02:38, 39.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:16:08,711] Trial 7 finished with value: 0.8370456798570107 and parameters: {'dropout_rate': 0.11080684372265459, 'learning_rate': 0.00011485897383928687, 'batch_size': 8}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  70%|███████   | 7/10 [05:09<01:38, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:16:27,672] Trial 6 finished with value: 0.8322296484079039 and parameters: {'dropout_rate': 0.18917524964141058, 'learning_rate': 0.00012194559158878622, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  80%|████████  | 8/10 [05:57<01:14, 37.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:17:14,923] Trial 8 finished with value: 0.8404178969080466 and parameters: {'dropout_rate': 0.2809698089557967, 'learning_rate': 0.00043355846691961236, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581:  90%|█████████ | 9/10 [07:34<00:56, 56.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:18:51,926] Trial 9 finished with value: 0.823986402491796 and parameters: {'dropout_rate': 0.17509720367918657, 'learning_rate': 2.0272016135619728e-05, 'batch_size': 4}. Best is trial 0 with value: 0.8405809951239277.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.840581: 100%|██████████| 10/10 [07:43<00:00, 46.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-27 17:19:01,510] Trial 2 finished with value: 0.8275270725048054 and parameters: {'dropout_rate': 0.13672153764063116, 'learning_rate': 1.4160299726084621e-05, 'batch_size': 2}. Best is trial 0 with value: 0.8405809951239277.\n",
      "dir(study) ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_ask', '_directions', '_get_trials', '_is_multi_objective', '_log_completed_trial', '_pop_waiting_trial_id', '_should_skip_enqueue', '_stop_flag', '_storage', '_study_id', '_tell', '_thread_local', 'add_trial', 'add_trials', 'ask', 'best_params', 'best_trial', 'best_trials', 'best_value', 'direction', 'directions', 'enqueue_trial', 'get_trials', 'metric_names', 'optimize', 'pruner', 'sampler', 'set_metric_names', 'set_system_attr', 'set_user_attr', 'stop', 'study_name', 'system_attrs', 'tell', 'trials', 'trials_dataframe', 'user_attrs']\n",
      "Best trial:\n",
      "-> Best score: 0.8405809951239277\n",
      "-> Optimal hyperparameters: \n",
      "{'batch_size': 4,\n",
      " 'dropout_rate': 0.2582012910782223,\n",
      " 'learning_rate': 0.0004393653708624279}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10, n_jobs=4, show_progress_bar=True)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print('dir(study)', dir(study))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'-> Best score: {trial.value}')\n",
    "print(f'-> Optimal hyperparameters: ')\n",
    "pprint.pprint(trial.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4,\n",
      " 'dropout_rate': 0.2582012910782223,\n",
      " 'learning_rate': 0.0004393653708624279}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Best model F1=0.839\n"
     ]
    }
   ],
   "source": [
    "def train_best_model(best_params):\n",
    "    batch_size = best_params.pop('batch_size', BATCH_SIZE)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    best_model = build_model(**best_params)\n",
    "    best_model.fit(X_train, Y_train, batch_size=batch_size, epochs=MAX_EPOCHS, validation_split=0.2,\n",
    "                callbacks=[early_stopping], verbose=3)\n",
    "    Y_predict = sigmoid(best_model(X_train))\n",
    "    f1_score = metrics.f1_score(Y_train, Y_predict)\n",
    "    print(f'Best model F1={f1_score:.3f}')\n",
    "    return best_model\n",
    "\n",
    "best_model = train_best_model(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                8880      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,169\n",
      "Trainable params: 9,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 17:02:38.629705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-27 17:02:38.637405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-27 17:02:38.720839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-03-27 17:02:38.737128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL-05/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL-05/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(SCRIPT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./test_enriched.csv', index_col='id')\n",
    "df_test.fillna({'keyword': '', 'location': '', 'country': '', 'state': '', 'city': '', 'url_domains': ''}, inplace=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 384)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embedding = None\n",
    "with open('./test-text-embeddings.pkl', 'rb') as fin:\n",
    "    test_embedding = pickle.load(fin)\n",
    "len(test_embedding), len(test_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape (3263, 554)\n"
     ]
    }
   ],
   "source": [
    "embedding_transformer.data = test_embedding\n",
    "X_test = transformer.transform(df_test)\n",
    "print('X_test shape', X_test.shape)\n",
    "\n",
    "Y_test_predict = sigmoid(best_model(X_test))\n",
    "\n",
    "df_example = pd.read_csv('./sample_submission.csv')\n",
    "df_example['target'] = Y_test_predict\n",
    "\n",
    "df_example.to_csv(f'./{SCRIPT_NAME}-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
