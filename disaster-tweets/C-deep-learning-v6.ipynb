{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster tweets DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 22:19:06.312049: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-04 22:19:06.357977: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/gangel/anaconda3/envs/machine-learning-1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import base, feature_extraction, ensemble, model_selection, pipeline, compose, preprocessing, metrics\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "import tensorflow as tf\n",
    "from embedding_transformer import Doc2VecTransformer\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import optuna\n",
    "import pprint\n",
    "\n",
    "SCRIPT_NAME='DL-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>positive_factor</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>missing_location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_content</th>\n",
       "      <th>...</th>\n",
       "      <th>punct_factor</th>\n",
       "      <th>ann_count</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>tokens_count</th>\n",
       "      <th>stop_words_factor</th>\n",
       "      <th>clean_tokens_factor</th>\n",
       "      <th>url_domains</th>\n",
       "      <th>url_redirects_count</th>\n",
       "      <th>hashtags_sentiment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.615385</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.590909</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.647059</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword  positive_factor location country state city  missing_location  \\\n",
       "id                                                                          \n",
       "0                       0.5                                             1   \n",
       "1                       0.5                                             1   \n",
       "2                       0.5                                             1   \n",
       "3                       0.5                                             1   \n",
       "4                       0.5                                             1   \n",
       "\n",
       "                                                 text  \\\n",
       "id                                                      \n",
       "0   Our Deeds are the Reason of this #earthquake M...   \n",
       "1              Forest fire near La Ronge Sask. Canada   \n",
       "2   All residents asked to 'shelter in place' are ...   \n",
       "3   13,000 people receive #wildfires evacuation or...   \n",
       "4   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "id                                                      \n",
       "0          deed reason earthquake may allah forgive u   \n",
       "1               forest fire near la ronge sask canada   \n",
       "2   resident asked shelter place notified officer ...   \n",
       "3   people receive wildfire evacuation order calif...   \n",
       "4   got sent photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                         text_content  ...  punct_factor  \\\n",
       "id                                                     ...                 \n",
       "0   Our Deeds are the Reason of this #earthquake M...  ...      0.017544   \n",
       "1              Forest fire near La Ronge Sask. Canada  ...      0.031250   \n",
       "2   All residents asked to 'shelter in place' are ...  ...      0.026786   \n",
       "3   13,000 people receive #wildfires evacuation or...  ...      0.035088   \n",
       "4   Just got sent this photo from Ruby #Alaska as ...  ...      0.027778   \n",
       "\n",
       "    ann_count  urls_count  tokens_count  stop_words_factor  \\\n",
       "id                                                           \n",
       "0           0           0            13           0.384615   \n",
       "1           0           0             7           0.000000   \n",
       "2           0           0            22           0.409091   \n",
       "3           0           0             9           0.111111   \n",
       "4           0           0            17           0.352941   \n",
       "\n",
       "    clean_tokens_factor  url_domains  url_redirects_count  hashtags_sentiment  \\\n",
       "id                                                                              \n",
       "0              0.615385                                 0            1.000000   \n",
       "1              1.000000                                 0            0.000000   \n",
       "2              0.590909                                 0            0.000000   \n",
       "3              0.888889                                 0            1.000000   \n",
       "4              0.647059                                 0            0.714286   \n",
       "\n",
       "   target  \n",
       "id         \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train_enriched.csv', index_col='id')\n",
    "df_train.fillna({'keyword': '', 'location': '', 'country': '', 'state': '', 'city': '', 'url_domains': '', 'clean_text': ''}, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = None\n",
    "with open('./train-text-embeddings.pkl', 'rb') as fin:\n",
    "    text_embedding = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embedding), len(text_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalEmbeddingTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, data):\n",
    "        # Store the embeddings and mode\n",
    "        self.data = data\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting necessary, return self\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X, self.data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (7613, 553)\n",
      "X_train type=<class 'numpy.ndarray'>, shape=(7613, 553)\n",
      "Y_train shape=(7613,)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\n",
    "    'country',\n",
    "    'state',\n",
    "]\n",
    "numerical_features = [\n",
    "    'text_length', \n",
    "    # 'ann_count',\n",
    "    # 'url_redirects_count',\n",
    "    # 'stop_words_factor',\n",
    "    'positive_factor',\n",
    "    # 'hashtags_sentiment'\n",
    "]\n",
    "\n",
    "# domains_vec = feature_extraction.text.TfidfVectorizer(max_features=100)\n",
    "# domains_vec = feature_extraction.text.CountVectorizer(max_features=100)\n",
    "\n",
    "column_transformer = compose.ColumnTransformer(transformers=[\n",
    "    # ('domains_vec', domains_vec, 'url_domains'),\n",
    "    ('one_hot', preprocessing.OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "    ('numerical', preprocessing.StandardScaler(), numerical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "embedding_transformer = ConditionalEmbeddingTransformer(text_embedding)\n",
    "\n",
    "transformer = pipeline.Pipeline([\n",
    "    ('columns', column_transformer),\n",
    "    ('text_embedding', embedding_transformer)\n",
    "])\n",
    "\n",
    "transformer.fit(df_train)\n",
    "X_train = transformer.transform(df_train)\n",
    "print('X_train shape', X_train.shape)\n",
    "\n",
    "Y_train = df_train['target']\n",
    "\n",
    "print(f'X_train type={type(X_train)}, shape={X_train.shape}')\n",
    "print(f'Y_train shape={Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X_train.shape[1]\n",
    "OUTPUT_SIZE = 1\n",
    "NN_SHAPE = [INPUT_SIZE, 64, 64, 1]\n",
    "BATCH_SIZE= X_train.shape[0]\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return tf.cast(tf.greater(tf.nn.sigmoid(x), .5), tf.int32)\n",
    "\n",
    "\n",
    "def build_model(layer_dims, use_dropout=False, dropout_rate_1=0.3, dropout_rate_2=0.1,\n",
    "                learning_rate=1e-3, \n",
    "                use_emma=False, emma_momentum=0.99, \n",
    "                use_regularizer=False, regularizer=0.01,\n",
    "                initializer='glorot_normal',\n",
    "                activation='relu'\n",
    "                ):\n",
    "    n_layers = len(layer_dims)\n",
    "    layers = []\n",
    "\n",
    "    for l in range(1, n_layers-1):\n",
    "        layer_kws = {}\n",
    "\n",
    "        if use_regularizer:\n",
    "            layer_kws['kernel_regularizer'] = tf.keras.regularizers.l2(regularizer)\n",
    "        if initializer:\n",
    "            layer_kws['kernel_initializer'] = initializer\n",
    "        \n",
    "        hidden_layer= tf.keras.layers.Dense(layer_dims[l], input_shape=(layer_dims[l-1],), activation=activation, **layer_kws)\n",
    "        \n",
    "        layers.append(hidden_layer)\n",
    "        \n",
    "        if use_dropout:\n",
    "            if l==1:\n",
    "                rate = dropout_rate_1\n",
    "            elif l==2 and n_layers > 3:\n",
    "                rate = dropout_rate_2\n",
    "            else:\n",
    "                rate = 0.0\n",
    "            if rate > .0:\n",
    "                layers.append(tf.keras.layers.Dropout(rate=rate))\n",
    "    layers.append(tf.keras.layers.Dense(layer_dims[n_layers-1], activation='linear'))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, use_ema=use_emma, ema_momentum=emma_momentum),                 \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics='accuracy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    use_dropout = False # trial.suggest_categorical('use_dropout', [True, False])\n",
    "    dropout_rate_1 = .0 # trial.suggest_float('dropout_rate_1', 0.1, 0.4) if use_dropout else .0\n",
    "    dropout_rate_2 = .0 # trial.suggest_float('dropout_rate_2', 0.0, 0.2) if use_dropout else .0\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [BATCH_SIZE, BATCH_SIZE//2 + 1, BATCH_SIZE//4 + 1])\n",
    "    use_emma = False # trial.suggest_categorical('use_emma', [True, False])\n",
    "    emma_momentum =.0 # trial.suggest_float('emma_momentum', 0.5, 0.9, log=True) if use_emma else 0.999\n",
    "    regularizer = trial.suggest_float('regularizer', 1e-5, 1e-2, log=True)\n",
    "    initializer = trial.suggest_categorical('initializer', ['glorot_normal', 'he_normal'])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'gelu', 'leaky_relu'])\n",
    "\n",
    "    k = 5  # Number of validations\n",
    "    shuffle_split = model_selection.StratifiedShuffleSplit(n_splits=k, test_size=0.2)\n",
    "    cvscores = []\n",
    "\n",
    "    model = build_model(layer_dims=NN_SHAPE, \n",
    "                        use_dropout=use_dropout, dropout_rate_1=dropout_rate_1, dropout_rate_2=dropout_rate_2,\n",
    "                        initializer=initializer,\n",
    "                        regularizer=regularizer, \n",
    "                        activation=activation,\n",
    "                        learning_rate=learning_rate, use_emma=use_emma, emma_momentum=emma_momentum)\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "    for index, datasets in enumerate(shuffle_split.split(X_train, Y_train)):\n",
    "        train, test = datasets\n",
    "        X_train_set = X_train[train]\n",
    "        Y_train_set = Y_train[train]\n",
    "        X_test_set = X_train[test]\n",
    "        Y_test_set = Y_train[test]\n",
    "        # print(f'---- step {index+1} of {k}')\n",
    "        # print(f'train size: {len(X_train_set)}, test size: {len(X_test_set)}')\n",
    "        \n",
    "        model.fit(X_train_set, Y_train_set, batch_size=batch_size, epochs=MAX_EPOCHS, \n",
    "                validation_data=(X_test_set, Y_test_set),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=0)\n",
    "\n",
    "        Y_predict = sigmoid(model.predict(X_test_set))\n",
    "\n",
    "        f1_score = metrics.f1_score(Y_test_set, Y_predict)\n",
    "        # print(f\"Validation F1: {f1_score}\")\n",
    "\n",
    "        cvscores.append(f1_score)\n",
    "\n",
    "    score = np.mean(cvscores)\n",
    "    print(f\"Mean cross-validation F1 score: {score}\")\n",
    "    # print(f\"Standard deviation of cross-validation score: {tf.math.reduce_std(cvscores)}\")\n",
    "    # print(model.summary())\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name=SCRIPT_NAME\n",
    "storage=f\"sqlite:///{SCRIPT_NAME}.optuna.db\"\n",
    "\n",
    "# recreate study for new NN architecture\n",
    "try:\n",
    "    optuna.delete_study(study_name=study_name, storage=storage)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 22:22:48,460] A new study created in RDB with name: DL-06\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 955us/step\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 919us/step\n",
      "48/48 [==============================] - 0s 928us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.743431:  10%|█         | 1/10 [00:05<00:53,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.743430942186669\n",
      "[I 2024-04-04 22:22:54,363] Trial 0 finished with value: 0.743430942186669 and parameters: {'learning_rate': 0.00031489116479568613, 'batch_size': 7613, 'regularizer': 2.9380279387035334e-05, 'initializer': 'glorot_normal', 'activation': 'relu'}. Best is trial 0 with value: 0.743430942186669.\n",
      "48/48 [==============================] - 0s 990us/step\n",
      "48/48 [==============================] - 0s 869us/step\n",
      "48/48 [==============================] - 0s 833us/step\n",
      "48/48 [==============================] - 0s 872us/step\n",
      "48/48 [==============================] - 0s 844us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.743431:  20%|██        | 2/10 [00:11<00:45,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.699155844249646\n",
      "[I 2024-04-04 22:22:59,986] Trial 1 finished with value: 0.699155844249646 and parameters: {'learning_rate': 1.2087541473056957e-05, 'batch_size': 7613, 'regularizer': 3.511356313970405e-05, 'initializer': 'he_normal', 'activation': 'relu'}. Best is trial 0 with value: 0.743430942186669.\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 972us/step\n",
      "48/48 [==============================] - 0s 903us/step\n",
      "48/48 [==============================] - 0s 914us/step\n",
      "48/48 [==============================] - 0s 874us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.806932:  30%|███       | 3/10 [00:15<00:33,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.8069321037289597\n",
      "[I 2024-04-04 22:23:03,605] Trial 2 finished with value: 0.8069321037289597 and parameters: {'learning_rate': 0.0028016351587162596, 'batch_size': 1904, 'regularizer': 0.00023345864076016249, 'initializer': 'glorot_normal', 'activation': 'gelu'}. Best is trial 2 with value: 0.8069321037289597.\n",
      "48/48 [==============================] - 0s 830us/step\n",
      "48/48 [==============================] - 0s 802us/step\n",
      "48/48 [==============================] - 0s 827us/step\n",
      "48/48 [==============================] - 0s 773us/step\n",
      "48/48 [==============================] - 0s 781us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  40%|████      | 4/10 [00:18<00:25,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.8084019932237224\n",
      "[I 2024-04-04 22:23:07,059] Trial 3 finished with value: 0.8084019932237224 and parameters: {'learning_rate': 0.0026926469100861782, 'batch_size': 1904, 'regularizer': 0.00788671412999049, 'initializer': 'glorot_normal', 'activation': 'gelu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 877us/step\n",
      "48/48 [==============================] - 0s 899us/step\n",
      "48/48 [==============================] - 0s 2ms/step\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 863us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  50%|█████     | 5/10 [00:25<00:26,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.2706746754961221\n",
      "[I 2024-04-04 22:23:14,145] Trial 4 finished with value: 0.2706746754961221 and parameters: {'learning_rate': 3.077180271250682e-05, 'batch_size': 1904, 'regularizer': 5.9750279999602906e-05, 'initializer': 'glorot_normal', 'activation': 'gelu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 787us/step\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "48/48 [==============================] - 0s 878us/step\n",
      "48/48 [==============================] - 0s 868us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  60%|██████    | 6/10 [00:28<00:18,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.7658286639530932\n",
      "[I 2024-04-04 22:23:17,397] Trial 5 finished with value: 0.7658286639530932 and parameters: {'learning_rate': 0.07556810141274425, 'batch_size': 3807, 'regularizer': 0.0006218704727769079, 'initializer': 'glorot_normal', 'activation': 'leaky_relu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 915us/step\n",
      "48/48 [==============================] - 0s 816us/step\n",
      "48/48 [==============================] - 0s 771us/step\n",
      "48/48 [==============================] - 0s 778us/step\n",
      "48/48 [==============================] - 0s 829us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  70%|███████   | 7/10 [00:34<00:14,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.7727282125329069\n",
      "[I 2024-04-04 22:23:23,008] Trial 6 finished with value: 0.7727282125329069 and parameters: {'learning_rate': 0.00035868164986275477, 'batch_size': 3807, 'regularizer': 6.963114377829287e-05, 'initializer': 'glorot_normal', 'activation': 'leaky_relu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 789us/step\n",
      "48/48 [==============================] - 0s 712us/step\n",
      "48/48 [==============================] - 0s 772us/step\n",
      "48/48 [==============================] - 0s 701us/step\n",
      "48/48 [==============================] - 0s 673us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  80%|████████  | 8/10 [00:37<00:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.8037977494320355\n",
      "[I 2024-04-04 22:23:25,840] Trial 7 finished with value: 0.8037977494320355 and parameters: {'learning_rate': 0.012273800987852962, 'batch_size': 1904, 'regularizer': 0.001319994226153501, 'initializer': 'he_normal', 'activation': 'gelu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 779us/step\n",
      "48/48 [==============================] - 0s 738us/step\n",
      "48/48 [==============================] - 0s 802us/step\n",
      "48/48 [==============================] - 0s 686us/step\n",
      "48/48 [==============================] - 0s 690us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402:  90%|█████████ | 9/10 [00:40<00:03,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.7933505280948496\n",
      "[I 2024-04-04 22:23:28,501] Trial 8 finished with value: 0.7933505280948496 and parameters: {'learning_rate': 0.028340904295147733, 'batch_size': 7613, 'regularizer': 8.569331925053983e-05, 'initializer': 'he_normal', 'activation': 'gelu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "48/48 [==============================] - 0s 714us/step\n",
      "48/48 [==============================] - 0s 743us/step\n",
      "48/48 [==============================] - 0s 731us/step\n",
      "48/48 [==============================] - 0s 827us/step\n",
      "48/48 [==============================] - 0s 790us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.808402: 100%|██████████| 10/10 [00:44<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation F1 score: 0.6763480087419891\n",
      "[I 2024-04-04 22:23:33,318] Trial 9 finished with value: 0.6763480087419891 and parameters: {'learning_rate': 3.0086868214458443e-05, 'batch_size': 3807, 'regularizer': 0.002055424552015075, 'initializer': 'he_normal', 'activation': 'relu'}. Best is trial 3 with value: 0.8084019932237224.\n",
      "-> Best score: 0.8084019932237224\n",
      "-> Optimal hyperparameters: \n",
      "{'activation': 'gelu',\n",
      " 'batch_size': 1904,\n",
      " 'initializer': 'glorot_normal',\n",
      " 'learning_rate': 0.0026926469100861782,\n",
      " 'regularizer': 0.00788671412999049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=study_name, storage=storage,\n",
    "                            direction='maximize', \n",
    "                            sampler=optuna.samplers.TPESampler(seed=42, consider_prior=True),\n",
    "                            load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "# Print optimal hyperparameters and the corresponding score\n",
    "\n",
    "trial = study.best_trial\n",
    "print(f'-> Best score: {trial.value}')\n",
    "print(f'-> Optimal hyperparameters: ')\n",
    "pprint.pprint(trial.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Best score: 0.8618254341828041\n",
      "{'emma_momentum': 0.9585386269812564,\n",
      " 'learning_rate': 0.00031489116479568613,\n",
      " 'regularizer': 2.9380279387035334e-05,\n",
      " 'use_emma': True}\n"
     ]
    }
   ],
   "source": [
    "print(f'-> Best score: {trial.value}')\n",
    "pprint.pprint(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gangel/anaconda3/envs/machine-learning-1/lib/python3.11/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Best model F1=0.878\n"
     ]
    }
   ],
   "source": [
    "def train_best_model(best_params):\n",
    "    batch_size = best_params.pop('batch_size', BATCH_SIZE)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    best_model = build_model(layer_dims=NN_SHAPE, **best_params)\n",
    "    best_model.fit(X_train, Y_train, batch_size=batch_size, epochs=MAX_EPOCHS, validation_split=0.2,\n",
    "                callbacks=[early_stopping], verbose=3)\n",
    "    Y_predict = sigmoid(best_model(X_train))\n",
    "    f1_score = metrics.f1_score(Y_train, Y_predict)\n",
    "    print(f'Best model F1={f1_score:.3f}')\n",
    "    return best_model\n",
    "\n",
    "best_model = train_best_model(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 2048)              1136640   \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,300,481\n",
      "Trainable params: 3,300,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL-06/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL-06/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(SCRIPT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./test_enriched.csv', index_col='id')\n",
    "df_test.fillna({'keyword': '', 'location': '', 'country': '', 'state': '', 'city': '', 'url_domains': ''}, inplace=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embedding = None\n",
    "with open('./test-text-embeddings.pkl', 'rb') as fin:\n",
    "    test_embedding = pickle.load(fin)\n",
    "len(test_embedding), len(test_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape (3263, 554)\n"
     ]
    }
   ],
   "source": [
    "embedding_transformer.data = test_embedding\n",
    "X_test = transformer.transform(df_test)\n",
    "print('X_test shape', X_test.shape)\n",
    "\n",
    "Y_test_predict = sigmoid(best_model(X_test))\n",
    "\n",
    "df_example = pd.read_csv('./sample_submission.csv')\n",
    "df_example['target'] = Y_test_predict\n",
    "\n",
    "df_example.to_csv(f'./{SCRIPT_NAME}-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
